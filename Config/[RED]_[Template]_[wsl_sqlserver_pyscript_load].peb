{# -- TemplateVersion:001 MinVersion:8510 MaxVersion:* TargetType:SqlServer ModelType:* TemplateType:Python Script                                            -- #}
{#                                                                                                                                                           -- #}
{# --    (c) WhereScape Inc 2024. WhereScape Inc permits you to copy this Template solely for use with the RED software, and to modify this Template         -- #}
{# --    for the purposes of using that modified Template with the RED software, but does not permit copying or modification for any other purpose.          -- #}
{# --                                                                                                                                                        -- #}
{# -- =============================================================================                                                                          -- #}
{# --                                                                                                                                                        -- #}
{# -- DBMS Name          : AzureSQ                                                                                                                           -- #}
{# -- Template Name      : wsl_sqlserver_pyscript_load                                                                                                       -- #}
{# -- RED Version        : 10.0.0.3                                                                                                                          -- #}
{# -- Description        : This template creates a AzureSQL script specifically                                                                              -- #}
{# --                      specifically designed for all RED load tables                                                                                     -- #}
{# --                                                                                                                                                        -- #}
{# -- =============================================================================                                                                          -- #}
{# --                                                                                                                                                        -- #}
{# --                                                                                                                                                        -- #}
{#  Notes / History                                                                                                                                          -- #}

#=============================================================================={%- br %}
# DBMS Name        :    AzureSQL {{table.dbType.name}}{%- br %}
# Template         :    {{settings.template.name}}{%- br %}
# Template Version :    8.5.1.0{%- br %}
# Description      :    Load {{table.name}}{%- br %}
# Generated by     :    {{env.productVersion}}{%- br %}
# Generated for    :    {{env.licensedTo}}{%- br %}
# Generated on     :    {{env.currentTimestamp}}{%- br %}
# Author           :    {{env.userName}}{%- br %}
{% if (table.loadInfo.sourceSchema) is defined %}
{% if (table.loadInfo.sourceSchema != "") and (table.loadInfo.sourceTables != "") %}
# Source Schema    :    {{table.loadInfo.sourceSchema}}{%- br %}
# Source Table     :    {{table.loadInfo.sourceTables}}{%- br %}
{% endif %}
{% endif %}
#=============================================================================={%- br %}
# Notes / History{%- br %}
#{%- br %}

{% import "wsl_sqlserver_utility" %}

import os{%br%}
import sys{%br%}
import pyodbc{%br%}
import glob{%br%}
from datetime import datetime{%br%}
import shutil{%br%}
import json{%br%}
import traceback{%br%}


path_to_WslPythonCommon = r"$WSL_SCRIPT_WslPythonCommon_CODE$"
path_to_SQLServer = r"$WSL_SCRIPT_WslPythonSQLServer_CODE$"

import WslPythonCommon{%br%}
import WslPythonSQLServer{%br%}

if sys.platform == 'win32':{%br%}
    WslPythonCommon.HideWindow(){%br%}


# ========================================================
# = Check Source Connection & Assign Run Mode
# ========================================================
{%- if (table.loadInfo.sourceConnectionType.name == "Configured Source Connection") and (table.loadInfo.sourceFile.path contains 's3://') -%}
{% set RunMode = "S3" %}{%- br %}
runMode = "S3" {%- br %}
{%- elseif (table.loadInfo.sourceConnectionType.name == "Configured Source Connection") and  (table.loadInfo.sourceFile.path contains 'gs://') -%}
{% set RunMode = 'GCS' %}{%- br %}
runMode = "GCS" {%- br %}
{%- elseif (table.loadInfo.sourceConnectionType.name == "Configured Source Connection") and  (table.loadInfo.sourceFile.path contains 'dfs.core.windows.net') -%}
{% set RunMode = 'AZ' %}{%- br %}
runMode = "AZ" {%- br %}
{%- elseif (table.loadInfo.sourceConnectionType.name == "Configured Source Connection") and  (table.loadInfo.uiConfigLoadProperties.restUrl is defined) -%}
{%- set restUrl = table.loadInfo.uiConfigLoadProperties.restUrl -%}
{% set RunMode = 'REST' %}{%- br %}
runMode = "REST" {%- br %}
{%- elseif (table.loadInfo.sourceConnectionType.name == "Configured Source Connection") and  (table.loadInfo.uiConfigLoadProperties.salesforceUrl is defined) -%}
{%- set salesURL = table.loadInfo.uiConfigLoadProperties.salesforceUrl -%}
{% set RunMode = 'Salesforce' %}{%- br %}
runMode = "Salesforce" {%- br %}
{%- elseif (table.loadInfo.sourceConnectionType.name == "ODBC") or (table.loadInfo.sourceConnectionType.name == "Database") -%}
{% set RunMode = 'Database' %}{%- br %}
runMode = "Database" {%- br %}
{%- else -%}
{% set RunMode = 'Windows' %}{%- br %}
runMode = "Windows" {%- br %}
{%- endif %}

{% set datasource = getExtendedProperty(propertyName ="TEMP_DATA_SOURCE") -%}

{%- if datasource | trim != "" %}
    {% set ServerType = 'AZSQL' %}{%- br %}
{%- else -%}
    {% set ServerType = 'SQL' %}{%- br %}
{%- endif %}

{% set unicode = getExtendedProperty(propertyName ="AZ_UNICODE_SUPPORT") | trim | upper -%}

{# --# ========================================================#}
{# --# = Check for Source File Types#}
{# --# ========================================================#}
{%- fetch table.loadInfo.sourceConnection -%}
{%- set fileType ="" -%}
{%- set filePattern = "false" -%}
{%- if (table.loadInfo.sourceConnectionType.name == "Configured Source Connection")-%}
{%- if table.loadInfo.uiConfigLoadProperties.fileType is defined -%}
    {%- set fileType = table.loadInfo.uiConfigLoadProperties.fileType | lower  -%}
    {%- if fileType == 'delimited' -%}
        {%- set fileType = 'csv' -%}
    {%- endif -%}
{%- elseif table.loadInfo.sourceFile.name != "" -%}
    {%- set fileType = 'fixwidth' -%}
    {% if table.loadInfo.sourceFile.fieldDelimiter | trim != '' %}
        {%- set fileType = 'csv' -%}
    {%- endif -%}
    {%- set foo = table.loadInfo.sourceFile.name -%}
    {%- set lngth = foo | length -%}
    {%- set dot = foo.indexOf(".")+1 -%}
    {%- set fileEx = foo | slice(dot, lngth) -%}
    {%- if fileEx contains "*" and not fileEx == '*'-%}
        {%- set lngth = foo | length -%}
        {%- set dot = foo.indexOf("*")+1 -%}
        {%- set fileEx = foo | slice(dot, lngth) -%}
        {%- set lngth = fileEx | length -%}
        {%- set dot = fileEx.indexOf("*")+1 -%}
        {%- set fileEx = fileEx | slice(dot, lngth) -%}
        {%- set filePattern = "true" -%}
    {%- endif -%}
    {%- if fileEx contains "." -%}
        {%- set lngth = foo | length -%}
        {%- set dot = foo.indexOf(".")+1 -%}
        {%- set fileEx = foo | slice(dot, lngth) -%}
        {%- set lngth = fileEx | length -%}
        {%- set dot = fileEx.indexOf(".")+1 -%}
        {%- set fileEx = fileEx | slice(dot, lngth) -%}
        {%- set foo = table.loadInfo.sourceFile.name | replace({"." + fileEx :""}) -%}
        {%- set lngth = foo | length -%}
        {%- set dot = foo.indexOf(".")+1 -%}
        {%- set fileSheet = foo | slice(dot, lngth) -%}
        {%- set fileName = table.loadInfo.sourceFile.name | replace({"." + fileSheet :""}) -%}
        {%- set fileNameCsv = fileName | replace({fileEx:"csv"}) -%}
    {%- endif -%}
    {%- if ['json','parquet','xml','avro','orc'] contains fileEx -%}
        {%- set fileType = fileEx -%}
    {%- elseif ['xls','xlsx'] contains fileEx-%}
        {%- set fileType = 'xlsx' -%}
    {%- endif -%}
{%- endif -%}
{%- endif -%}

{%- if fileType == "" -%}
{%- if ['json','parquet','xml','avro','orc'] contains table.loadInfo.sourceFile.name.split("\.") | last -%}
{%- set fileType = table.loadInfo.sourceFile.name.split("\.") | last -%}
{%- elseif ['xls','xlsx'] contains table.loadInfo.sourceFile.name.split("\.") | last -%}
{%- set fileType = 'xlsx' -%}
{%- else -%}
{%- set fileType = 'csv' -%}
{%- endif -%}
{%- br %}
{%- endif -%}


{# --# ========================================================#}
{# --# = Check for Archive Properties #}
{# --# ========================================================#}
{%- fetch table.loadInfo.sourceConnection -%}
{%- set sourceFileArchiveMode  = false -%}
{%- set triggerFileArchiveMode = false -%}
{% if (table.loadInfo.triggerArchiveFile.path | trim != "") %}{% br %}
    {%- set triggerFileArchiveMode = true -%}
{%- endif -%}
{% if (table.loadInfo.archiveFile.path | trim != "") %}{% br %}
    {%- set sourceFileArchiveMode = true -%}
{%- endif -%}


#--============================================================================{%br%}
#-- Init Logger{%br%}
#--============================================================================{%br%}
debugModeExt = WslPythonCommon.GetExtendedProperty("AZ_DEBUG_MODE", str(os.environ.get('WSL_LOAD_TABLE',''))).upper().strip()
{%br%}
{%- set type = "load" -%}
{% include "wsl_template_pyscript_utility" with { type: type }%}
{%br%}

{# == Import modules for REST API ============================================ #}
{% if RunMode == "REST" %}
{%- br %}
import requests{%br%}
import json{%br%}
try:
    WslApiFileBrowserNewPath = os.path.join(os.path.dirname(r'$WSL_SCRIPT_WslApiFileBrowser_CODE$'), "WslApiFileBrowser.py")
    os.replace(r'$WSL_SCRIPT_WslApiFileBrowser_CODE$', WslApiFileBrowserNewPath)
    sys.path.append(os.path.dirname(r'$WSL_SCRIPT_WslApiFileBrowser_CODE$'))
    import WslApiFileBrowser

    WslSampleAuthNewPath = os.path.join(os.path.dirname(r'$WSL_SCRIPT_WslSampleAuth_CODE$'), "WslSampleAuth.py")
    os.replace(r'$WSL_SCRIPT_WslSampleAuth_CODE$', WslSampleAuthNewPath)
    sys.path.append(os.path.dirname(r'$WSL_SCRIPT_WslSampleAuth_CODE$'))
    import WslSampleAuth as WslSampleAuthScript

except Exception:
    WslApiFileBrowser= __import__('WslApiFileBrowser')
    WslSampleAuthScript= __import__('WslSampleAuth')
{%- endif %}

{# == Import modules for Salesforce ============================================ #}
{% if RunMode == "Salesforce" %}
{%- br %}
import requests{%br%}
import json{%br%}
from simple_salesforce import Salesforce{%br%}
from requests.auth import HTTPBasicAuth{%br%}
from io import StringIO{%br%}
try: {%br%}
    WslApiFileBrowser = "$WSL_SCRIPT_WslApiFileBrowser_CODE$"
    WslApiFileBrowser = WslApiFileBrowser.split("\\")[-1][:-3]
    WslApiFileBrowser = __import__(WslApiFileBrowser)

    WslSampleAuth = "$WSL_SCRIPT_WslSampleAuth_CODE$"
    WslSampleAuth = WslSampleAuth.split("\\")[-1][:-3]
    WslSampleAuthScript = __import__(WslSampleAuth)

except Exception: {%br%}
    WslApiFileBrowser= __import__('WslApiFileBrowser')
    WslSampleAuthScript= __import__('WslSampleAuth')
{%- endif %}

#--============================================================================{%br%}
#-- Create Load Properties Object For Source Connection{%br%}
#--============================================================================{%br%}
loadTableProperties = {}

# -- Header --------------------------------------------
if "{{ table.loadInfo.sourceFile.headerLine }}" == "true":
    loadTableProperties['fieldHeading'] = 2
elif "{{ table.loadInfo.sourceFile.headerLine }}" == "false":
    loadTableProperties['fieldHeading'] = 1

# -- Source Path --------------------------------------------
loadTableProperties['sourceFilePath'] = r"{{ table.loadInfo.sourceFile.path }} ".strip()
{% if RunMode != "Database" %}
if loadTableProperties['sourceFilePath'][-1] == "/":
    loadTableProperties['sourceFilePath'] = loadTableProperties['sourceFilePath'][:-1]
{%- endif %}{%br%}


# -- Field Enclosure --------------------------------------------
loadTableProperties['sourceFileFieldEnclosure'] = '{{table.loadInfo.sourceFile.fieldEnclosure}}'

# -- Record Delimiter --------------------------------------------
loadTableProperties['sourceFileRecordDelimiter'] = """{{table.loadInfo.sourceFile.recordDelimiter}}"""
if loadTableProperties['sourceFileRecordDelimiter'].strip() == "":
    loadTableProperties['sourceFileRecordDelimiter'] ="\\n"

# -- Field Delimiter --------------------------------------------
loadTableProperties['sourceFileFieldDelimiter'] = '{{table.loadInfo.sourceFile.fieldDelimiter}}'

# -- File Name --------------------------------------------
{%- if fileType == "xlsx" %}
{%br%}
loadTableProperties['sourceFileName'] = r'{{ table.loadInfo.sourceFile.name }}'.split(".")[0]+"."+r'{{ table.loadInfo.sourceFile.name }}'.split(".")[2]
loadTableProperties['sourceFileSheetName'] = r'{{ table.loadInfo.sourceFile.name }}'.split(".")[1]
loadTableProperties['sourceFileNameCsv'] = r'{{ table.loadInfo.sourceFile.name }}'.split(".")[0]+".csv"
{%- else -%}
{%br%}
loadTableProperties['sourceFileName'] = r'{{ table.loadInfo.sourceFile.name }}'{%br%}
{%- endif %}

# -- File Type(Parser) --------------------------------------------
loadTableProperties['fileType'] = r'{{fileType}}'{% br %}

{%- set isTriggerFilePresent  = false -%}
{% if (table.loadInfo.triggerFile.path | trim != "") %}{% br %}
# -- Trigger File Properties --------------------------------------------
{%- set isTriggerFilePresent  = true -%}{%br%}
loadTableProperties['triggerFilePath'] = r"{{ table.loadInfo.triggerFile.path }} ".strip(){%br%}
loadTableProperties['triggerFileName'] = "{{ table.loadInfo.triggerFile.name }} ".strip(){%br%}
{%- endif -%}

{%- if (table.loadInfo.wait == true) %}{%br%}
# -- Wait Time --------------------------------------------
loadTableProperties['waitTime'] = {{table.loadInfo.waitSeconds}}{%br%}
{%- else -%}
{%br%}
loadTableProperties['waitTime'] = 1{%br%}
{%- endif %}


{%- if sourceFileArchiveMode == true %}
# -- Source Archive Properties --------------------------------------------
loadTableProperties['source_destination_directory'] = r"{{table.loadInfo.archiveFile.path}} ".strip()
loadTableProperties['source_destination_file_name'] = "{{ table.loadInfo.archiveFile.name }} ".strip()
{%- endif %}


{%- if triggerFileArchiveMode == true %}
# -- Trigger Archive Properties --------------------------------------------
loadTableProperties['trigger_destination_directory'] = r"{{ table.loadInfo.triggerArchiveFile.path }} ".strip()
loadTableProperties['trigger_destination_file_name'] = "{{ table.loadInfo.triggerArchiveFile.name }} ".strip()
{%- endif %}


# -- Load Table Properties --------------------------------------------
loadTableProperties['targetTableName'] = str(os.environ.get('WSL_LOAD_FULLNAME',''))
loadTableProperties['WSL_WORKDIR'] = os.environ.get('WSL_WORKDIR','')
loadTableProperties['auditLog'] = str(os.environ.get('WSL_LOAD_TABLE','')) + "_" + str(os.environ.get('WSL_SEQUENCE','')) + ".txt"


{% if (RunMode == "S3") %}
# -- Load Properties For Amazon S3  --------------------------------------------
loadTableProperties['awsAccessKey']=str(os.environ.get('ACCESS_KEY',''))
if loadTableProperties['awsAccessKey'].strip() =="":
    loadTableProperties['awsAccessKey']=str('$WSL_SRCCFG_s3AccessKey$')

loadTableProperties['awsSecretKey']=str(os.environ.get('SECRET_KEY',''))
if loadTableProperties['awsSecretKey'].strip() =="":
    loadTableProperties['awsSecretKey']=str(os.environ.get('WSL_SRCCFG_s3SecretKey'))

loadTableProperties['s3FileDetails'] = loadTableProperties['sourceFilePath'].replace("/ ","").strip()+"/" + loadTableProperties['sourceFileName']
loadTableProperties['s3RegionName'] = str('$WSL_SRCCFG_s3Region$')
loadTableProperties['s3BucketName'] = loadTableProperties['sourceFilePath'].replace("s3://","").split("/")[0]

if loadTableProperties['sourceFilePath'][-1] == "/":
    loadTableProperties['sourceFilePath'] = loadTableProperties['sourceFilePath'][0:-1]
{%- endif %}


{% if (RunMode == "GCS") %}
# -- Load Properties For Google Cloud Storage --------------------------------------------
loadTableProperties['gcsFileDetails'] = loadTableProperties['sourceFilePath']
{%- endif %}


{% if (RunMode == "AZ") %}
# -- Load Properties For Azure --------------------------------------------
file_path = r"{{ table.loadInfo.sourceFile.path }} ".strip() + r'/{{ table.loadInfo.sourceFile.name }}'.strip()
azureFileDetails = r"{{ table.loadInfo.sourceFile.path }}".strip() + r'/{{ table.loadInfo.sourceFile.name }}'.strip()
loadTableProperties['azureStorageAccountAccessKey'] = str(os.environ.get('WSL_SRCCFG_azureStorageAccountAccessKey'))
loadTableProperties['azureSasToken'] = str(os.environ.get('WSL_SRCCFG_azureSASToken'))
loadTableProperties['azureFileDetails'] = azureFileDetails
loadTableProperties['azureStorageAccountName'] = str(os.environ.get('WSL_SRCCFG_azureStorageAccountName'))
loadTableProperties['azureStorageFileSystem'] = str(r"{{ table.loadInfo.sourceFile.path }}".split("net")[1]) #str(os.environ.get('WSL_SRCCFG_azureStorageFileSystem'))
loadTableProperties['azureStorageFileSystemDirectory'] = str(os.environ.get('WSL_SRCCFG_azureStorageFileSystemDirectory'))
{%- endif %}{%br%}

{% if (RunMode == "REST") %}
# -- Load Properties REST API --------------------------------------------
loadTableProperties['restApiUrl'] = r"{{ restUrl }}"
loadTableProperties['restApiUserId'] = "$WSL_SRCCFG_APIUserId$".strip()
loadTableProperties['restApiPass'] = os.environ.get("WSL_SRCCFG_ApiPassword")
loadTableProperties['restApiHeader'] =  os.environ.get("WSL_SRCCFG_HeaderKey")
loadTableProperties['restApiRequestType'] = "$WSL_SRCCFG_APIMethod$".strip()
loadTableProperties['restApiPayload'] = os.environ.get("WSL_SRCCFG_Payload")
loadTableProperties['restResultType'] = "$WSL_SRCCFG_ResultType$".strip()

{%- endif %}{%br%}

{% if (RunMode == "Salesforce") %}
# -- Load Properties Salesforce  --------------------------------------------
loadTableProperties['salesforceUrl'] = r"{{ salesURL }}"
loadTableProperties['salesUserId'] = "$WSL_SRCCFG_SalesforceUserId$".strip()
loadTableProperties['salesPass'] = os.environ.get("WSL_SRCCFG_SalesforcePassword")
loadTableProperties['salesHeader'] =  os.environ.get("WSL_SRCCFG_SalesforceHeaderKey")
loadTableProperties['salesRequestType'] = "$WSL_SRCCFG_SalesAPIMethod$".strip()
loadTableProperties['salesPayload'] =os.environ.get("WSL_SRCCFG_SalesforcePayload")
loadTableProperties['salesResultType'] = "$WSL_SRCCFG_SalesforceResultType$".strip()
loadTableProperties['salessecurityToken']  =  os.environ.get("WSL_SRCCFG_SecurityToken")
loadTableProperties['salesforceQuery'] = "$WSL_SRCCFG_SalesforceObjectQuery$".strip()
loadTableProperties['salesinstance'] = "$WSL_SRCCFG_Instance$".strip()
{%- endif %}{%br%}


#--============================================================================{%br%}
#-- Create Extended Properties Object{%br%}
#--============================================================================{%br%}

try:
    {%br%}
    extendedProperty = {
        'DEBUG'                  : WslPythonCommon.GetExtendedProperty("AZ_DEBUG_MODE",str(os.environ.get('WSL_LOAD_TABLE',''))).upper().strip(),
        'UNICODE_SUPPORT'        : WslPythonCommon.GetExtendedProperty("AZ_UNICODE_SUPPORT",str(os.environ.get('WSL_LOAD_TABLE',''))),
        'UNLOAD_DELIMITER'       : WslPythonCommon.GetExtendedProperty("AZ_UNLOAD_DELIMITER",str(os.environ.get('WSL_LOAD_TABLE',''))),
        'UNLOAD_ENC'             : WslPythonCommon.GetExtendedProperty("AZ_UNLOAD_ENCLOSED_BY",str(os.environ.get('WSL_LOAD_TABLE',''))),
        'UNLOAD_ESC'             : WslPythonCommon.GetExtendedProperty("AZ_UNLOAD_ESCAPE_CHAR",str(os.environ.get('WSL_LOAD_TABLE',''))),
        'UNLOAD_RECORD_CHAR'     : WslPythonCommon.GetExtendedProperty("AZ_UNLOAD_RECORD_CHAR",str(os.environ.get('WSL_LOAD_TABLE',''))),
        'SPLIT_THRESHOLD'        : WslPythonCommon.GetExtendedProperty("AZ_SPLIT_THRESHOLD",str(os.environ.get('WSL_LOAD_TABLE',''))),
        'FILE_COUNT'             : WslPythonCommon.GetExtendedProperty("AZ_SPLIT_COUNT",str(os.environ.get('WSL_LOAD_TABLE',''))),
        'BLOB_STORAGE_ACCOUNT'   : WslPythonCommon.GetExtendedProperty("BLOB_ACCOUNT",str(os.environ.get('WSL_LOAD_TABLE',''))),
        'BLOB_STORAGE_ACCESS_KEY': WslPythonCommon.GetExtendedProperty("BLOB_KEY",str(os.environ.get('WSL_LOAD_TABLE',''))),
        'BLOB_STORAGE_CONTAINER' : WslPythonCommon.GetExtendedProperty("BLOB_TEMP_CONTAINER",str(os.environ.get('WSL_LOAD_TABLE',''))),
        'BLOB_DATA_SOURCE'       : WslPythonCommon.GetExtendedProperty("TEMP_DATA_SOURCE",str(os.environ.get('WSL_LOAD_TABLE',''))),
        'BLOB_ENDPOINT'          : WslPythonCommon.GetExtendedProperty("BLOB_ENDPOINT",str(os.environ.get('WSL_LOAD_TABLE','')))
    }{%- br %}
{%- br %}
    if str(extendedProperty['UNLOAD_DELIMITER']) == "": {%- br %}
        extendedProperty['UNLOAD_DELIMITER'] = '|' {%- br %}
    {%- br %}

    if str(extendedProperty['UNLOAD_RECORD_CHAR']) == "": {%- br %}
        extendedProperty['UNLOAD_RECORD_CHAR'] = '\\n' {%- br %}
    {%- br %}

    if str(extendedProperty['UNLOAD_ENC']) == "": {%- br %}
        extendedProperty['UNLOAD_ENC'] = '"' {%- br %}
    {%- br %}

    if extendedProperty['UNLOAD_ESC']=="":{%- br %}
        extendedProperty["UNLOAD_ESC"] = "#"{%- br %}
    {%- br %}

    unicode = False{% br %}
    if str(extendedProperty['UNICODE_SUPPORT']).upper() == "TRUE":{% br %}
        unicode = "utf-8"{% br %}
    else:
        unicode = "ascii"{% br %}
    {%- br %}

    if extendedProperty['SPLIT_THRESHOLD']=="" or int(extendedProperty['SPLIT_THRESHOLD'])==0 :{% br %}
        extendedProperty['SPLIT_THRESHOLD'] = 100000
    else:{% br %}
        extendedProperty['SPLIT_THRESHOLD'] = int(extendedProperty['SPLIT_THRESHOLD']){% br %}

    if str(extendedProperty['BLOB_ENDPOINT']) == "":{% br %}
        extendedProperty['BLOB_ENDPOINT'] = "core.windows.net"{% br %}
    else:{% br %}
        extendedProperty['BLOB_ENDPOINT'] = extendedProperty['BLOB_ENDPOINT']{% br %}

{%- br %}
except Exception as exceptionError:{%br%}
    write_error("Failed to create extended properties object: " + str(exceptionError))
    write_error(traceback.format_exc())
    exitCode = 2
    exitMessage = 'Script Failed to create extended properties object'
    raise exceptionError


#--============================================================================{%br%}
#-- Write Load Details To Log{%br%}
#--============================================================================{%br%}
write_audit("=================== LOAD OPTIONS ==================="){%br%}
write_audit("Specified Load Table:        " + str(os.environ.get('WSL_LOAD_TABLE',''))){%br%}
write_audit("Specified Work Dir:          " + str(loadTableProperties['WSL_WORKDIR'])){%br%}
write_audit("Specified Sequence:          " + str(os.environ.get('WSL_SEQUENCE',''))){%br%}
write_audit("Specified Metadata ODBC DSN: " + str(os.environ.get('WSL_META_DSN',''))){%br%}
write_audit("Specified Metadata Username: " + str(os.environ.get('WSL_META_USER',''))){%br%}
write_audit("Specified Metadata Password: " + ('*'*len(str(os.environ.get('WSL_META_PWD',''))))){%br%}
write_audit("")

write_audit("=================== MODES ==================="){%br%}
write_audit("Debug Mode:        " + str(extendedProperty['DEBUG'])){%br%}
write_audit("Run Mode:          " + runMode){%br%}
write_audit("Unicode Extract:   " + unicode){%br%}
write_audit("")

{% if RunMode == "Database" %}{%- br %}
write_audit("=================== SOURCE TABLE INFO ==================="){%br%}
write_audit("Source Schema:               " + str(os.environ.get('WSL_SRC_SCHEMA',''))){%br%}
write_audit("Source Tables:               " + '{{ table.loadInfo.sourceTables }}'){%br%}
write_audit("=================== SOURCE DB INFO ==================="){%br%}
write_audit("ODBC Source DSN:             " + str(os.environ.get('WSL_SRC_DSN',''))){%br%}
write_audit("ODBC Source Username:        " + str(os.environ.get('WSL_SRC_USER',''))){%br%}
write_audit("ODBC Source Password:        " + ('*'*len(str(os.environ.get('WSL_SRC_PWD',''))))){%br%}
{% else %}{%- br %}
write_audit("=================== SOURCE FILE INFO ==================="){%br%}
write_audit("Source File Header Line               " +str(loadTableProperties['fieldHeading'])){%br%}
write_audit("Source File Path                      " +loadTableProperties['sourceFilePath']){%br%}
write_audit("Source Field Enclosure                " +loadTableProperties['sourceFileFieldEnclosure']){%br%}
write_audit("Source Record Delimiter               " +loadTableProperties['sourceFileRecordDelimiter']){%br%}
write_audit("Source Field  Delimiter               " +loadTableProperties['sourceFileFieldDelimiter'] ){%br%}
write_audit("Source File Name                      " +loadTableProperties['sourceFileName'] ){%br%}
{%- endif %}
{%- if fileType == 'xlsx' %}
{%br%}
write_audit("Source Sheet Name                     " +loadTableProperties['sourceFileSheetName'] ){%br%}
write_audit("Source CSV File Name                  " +loadTableProperties['sourceFileNameCsv'] ){%br%}
{%- endif %}
write_audit("")

write_audit("=================== EXTENDED PROPERTIES ==================="){%br%}
write_audit("DEBUG_MODE:               " + str(extendedProperty['DEBUG'])){%br%}
write_audit("UNICODE_SUPPORT:          " + str(extendedProperty['UNICODE_SUPPORT'])){%br%}
write_audit("UNLOAD_DELIMITER:         " + str(extendedProperty['UNLOAD_DELIMITER'])){%br%}
write_audit("UNLOAD_ENC:               " + str(extendedProperty['UNLOAD_ENC'])){%br%}
write_audit("UNLOAD_ESC:               " + str(extendedProperty['UNLOAD_ESC'])){%br%}
write_audit("UNLOAD_RECORD_CHAR:       " + str(extendedProperty['UNLOAD_RECORD_CHAR'])){%br%}
write_audit("")
if str(os.environ.get('WSL_TGT_CONSTRING','')) != "":
    write_audit("Target connected with advanced connect method")
if str(os.environ.get('WSL_META_CONSTRING','')) != "":
    write_audit("Metadata connected with advanced connect method")
if str(os.environ.get('WSL_SRC_CONSTRING','')) != "":
    write_audit("Source connected with advanced connect method")

#--============================================================================{%br%}
#-- SQL Server Connection Function{%br%}
#--============================================================================{%br%}
def execute_sql_query(sql, dsn=str(os.environ.get('WSL_TGT_DSN','')), uid=str(os.environ.get('WSL_TGT_USER','')), pwd=str(os.environ.get('WSL_TGT_PWD',''))):
    try:
        if os.environ.get('WSL_TGT_CONSTRING','') != "":
            connection_string = os.environ.get('WSL_TGT_CONSTRING','')
        else:
            connection_string = "DSN=" + dsn
            if uid:
                connection_string += ";UID=" + uid
            if pwd:
                connection_string += ";PWD=" + pwd
        connection = pyodbc.connect(connection_string, autocommit=True)
        cursor = connection.cursor()
        result = cursor.execute(sql)
        return result.rowcount
    except Exception as exceptionError:
        raise exceptionError
{%br%}


def create_temp_table():
    temp_table_sql = """
    CREATE TABLE {{table.name}}_TMP
    {%- from table.columns as col where (col.transformType.code != "A") %}
    {%- if not loop.first %}                  ,     {% else %}                  (     {% endif %}
    {{- col.name }} {{ col.fullDataType }}{% br %}
    {%- endfrom %}                  ){% br %}
    """

    write_detail(temp_table_sql)
    try:
        execute_sql_query(temp_table_sql)
    except Exception as exceptionError:
        write_error("Failed to create temp table: " + str(exceptionError))
        write_error(traceback.format_exc())
        exitCode = 2
        exitMessage = 'Script failed to create temporary table'
        raise exceptionError


# Drop Temporary Table
def drop_temp_table():
    temp_table_sql = """
    DROP TABLE IF EXISTS {{table.name}}_TMP
    """
    write_detail(temp_table_sql)
    try:
        execute_sql_query(temp_table_sql)
    except Exception as exceptionError:
        write_error("Failed to drop temp table: " + str(exceptionError))
        write_error(traceback.format_exc())
        exitCode = 2
        exitMessage = 'Script failed to drop temporary table'
        raise exceptionError


def load_data(filePath): {%- br %}
    {%- if RunMode == "Database" or ['avro','orc', 'parquet', 'xlsx','xml','json'] contains fileType %}{%- br %}
    fieldDelimiter = str(extendedProperty['UNLOAD_DELIMITER'])
    recordDelimiter = str(extendedProperty['UNLOAD_RECORD_CHAR'])
    fieldEnclosure = str(extendedProperty['UNLOAD_ENC'])
    if fieldEnclosure == "'":
        fieldEnclosure = "''"
    {%- if RunMode == "Database"%}{%- br %}
    header = "2"{%- br %}
    {%- elseif ['avro','orc', 'parquet'] contains fileType %}{%- br %}
    header = "1"{%- br %}
    {%- else %}{%- br %}
    header = str(loadTableProperties['fieldHeading']){%- br %}
    {% endif %}

    {%- elseif fileType == "csv" %}{%- br %}
    fieldDelimiter = str(loadTableProperties['sourceFileFieldDelimiter'])
    recordDelimiter = str(extendedProperty['UNLOAD_RECORD_CHAR'])
    fieldEnclosure = str(loadTableProperties['sourceFileFieldEnclosure'])
    header = str(loadTableProperties['fieldHeading']){%- br %}
    {%- endif %}

    {%- if serverType == "AZSQL" %}{%- br %}
    dataSource = str(extendedProperty['BLOB_DATA_SOURCE'])
    blob_account = str(extendedProperty['BLOB_STORAGE_ACCOUNT'])
    container = str(extendedProperty['BLOB_STORAGE_CONTAINER'])
    filePath = f'{loadTableProperties["blob_name"]}/{filePath}'
    {%- endif %}


    bulk_load_sql = f"""
    BULK INSERT {{table.name}}_TMP
    FROM '{filePath}'
    WITH (
        FORMAT = 'CSV',
        FIELDTERMINATOR = '{fieldDelimiter}',
        ROWTERMINATOR = '{recordDelimiter}',
        FIELDQUOTE = '{fieldEnclosure}',
        FIRSTROW = {header},
        KEEPNULLS,
        {%- if unicode == "TRUE" %}{%- br %}
        CODEPAGE = '65001'
        {%- else -%}{%- br %}
        CODEPAGE = 'RAW'
        {%- endif %}
        {%- if serverType == "AZSQL" %}
        , DATA_SOURCE = '{dataSource}'
        {%- endif %}
    )
    """
    write_detail("=================== BULK LOAD ===================")
    write_detail(f"Running bulk load query for file: '{filePath}'")
    write_detail(bulk_load_sql)
    write_detail("=================================================")

    try:
        row_count = execute_sql_query(bulk_load_sql)
        return row_count, True
    except Exception as exceptionError:
        write_error("Failed to load data: " + str(exceptionError))
        write_error(traceback.format_exc())
        exitCode = 2
        exitMessage = 'Script failed to load data'
        raise exceptionError


# Insert Data Into Target Table
def insert_data():
    insert_sql = """
    INSERT INTO {{table.schema}}.{{table.name}}
    {%- from table.columns as col where (col.transformType.code != "A")  %}
    {%- if col.transformType.code != "A" %}
    {%- if not loop.first %}                  ,     {% else %}                  (     {% endif %}
    {{- col.name }}{% br %}
    {% endif %}
    {%- endfrom %}                  ){% br %}
    SELECT {% br %}
    {%- from table.columns as col where (col.transformType.code != "A")  %}
    {%- if col.transformType.code != "A" %}
    {%- if loop.first %}{% else %}    ,{% endif %}
    {%- if col.transform != "" and RunMode == 'Database'-%}
        {{col.name}}{%- br %}
    {%- elseif col.transform != "" %}
        {{- col.transform }}{%br%}
    {%- else %}
        {{col.name}}{%br%}
    {% endif %}
    {% endif %}
    {%- endfrom %}
    FROM {{table.name}}_TMP
    """

    write_detail("=================== INSERT DATA ===================")
    write_detail("Running insert query")
    write_detail(insert_sql)
    write_detail("==================================================")

    try:
        row_count = execute_sql_query(insert_sql)
        return row_count
    except Exception as exceptionError:
        write_error("Failed to insert data: " + str(exceptionError))
        write_error(traceback.format_exc())
        exitCode = 2
        exitMessage = 'Script failed to insert data'
        raise exceptionError


# ========================================================
# = Main Process Start Here
# ========================================================
try:{%- br %}
    {% if RunMode == "REST" %}
    # ========================================================
    # = Download REST API Result File
    # ========================================================
    restURL = loadTableProperties['restApiUrl']
    userId = loadTableProperties['restApiUserId']
    password = loadTableProperties['restApiPass']
    headers = loadTableProperties['restApiHeader']
    requestType = loadTableProperties['restApiRequestType']
    payload = loadTableProperties['restApiPayload']
    resultType = loadTableProperties['restResultType']
    {%- br %}

    # Check if headers and payload are empty {%- br %}
    if headers != None and headers != "": {%- br %}
        headers = json.loads(str(headers).replace("\'", "\"")) {%- br %}
    else: {%- br %}
        headers = None {%- br %}
    if payload != None and payload != "": {%- br %}
        payload = json.loads(str(payload).replace("\'", "\"")) {%- br %}
    else: {%- br %}
        payload = None {%- br %}
    if resultType == "": {%- br %}
        resultType = "GET" {%- br %}

    # Create restAPI {%- br %}
    restAPI = WslApiFileBrowser.Auth() {%- br %}

    # Create user custom auth {%- br %}
    userCustomRESTAuth = WslSampleAuthScript.UserAuth(restURL, userId, password, headers, requestType, payload) {%- br %}

    # Run entry point function of the user custom auth {%- br %}
    userCustomSession, userCustomHeader = userCustomRESTAuth.entryMethod() {%- br %}

    if userCustomHeader != headers: {%- br %}
        headers = userCustomHeader {%- br %}
    # If session generated by user custom auth is "Default", then execute our own auth function {%- br %}
    if userCustomSession == "Default": {%- br %}
        if userId and password: {%- br %}
            restAPI.basicAuthSession(userId, password) {%- br %}
            apiFileDownloadedPath = restAPI.basicAuthRequest(restAPI.session, requestType, restURL, resultType, headers, payload) {%- br %}
        else: {%- br %}
            apiFileDownloadedPath = restAPI.openRequest(requestType, restURL, resultType, headers) {%- br %}
    else: {%- br %}
        apiFileDownloadedPath = restAPI.userSessionCommonRequest(userCustomSession, requestType, restURL, headers, payload, resultType) {%- br %}

    downloadFolderName_rest = "wsl" + '_' +str(os.environ.get('WSL_LOAD_TABLE','')) + '_' + str(os.environ.get('WSL_SEQUENCE','')+'tmp')
    destination_folder = os.path.join(loadTableProperties['WSL_WORKDIR'],downloadFolderName_rest)
    os.makedirs(destination_folder, exist_ok=True)

    # Error Handling
    if "API_ERROR:" in apiFileDownloadedPath:
        write_error("Error in fetching API data")
        raise Exception("Error in fetching API data")

    if str(resultType) == "JSON": {%- br %}
        loadTableProperties['sourceFileName'] = "api.json" {%- br %}
    else:
        loadTableProperties['sourceFileName'] = "api.xml" {%- br %}
    destinationPath = os.path.join(destination_folder, loadTableProperties['sourceFileName'])
    shutil.move(apiFileDownloadedPath, destinationPath)
    loadTableProperties['sourceFilePath'] = destination_folder {%- br %}
    {%- br %}
    {%- endif %}
    {% if RunMode == "Salesforce" %}{%- br %}
    salesURL = loadTableProperties['salesforceUrl']
    salesId = loadTableProperties['salesUserId']
    salesPassword = loadTableProperties['salesPass']
    salesHeaders = loadTableProperties['salesHeader']
    salesRequestType = loadTableProperties['salesRequestType']
    salesPayload = loadTableProperties['salesPayload']
    salesResultType = loadTableProperties['salesResultType']
    instance =  loadTableProperties['salesinstance']
    securityToken =  loadTableProperties['salessecurityToken']
    salesforceQuery = loadTableProperties['salesforceQuery']
    if salesHeaders != None and salesHeaders != "":
        salesHeaders = json.loads(salesHeaders.replace("\'", "\""))
    else:
        salesHeaders = None
    if salesPayload != None and salesPayload != "":
        if salesResultType != "XML" and salesResultType != "CSV" :
            salesPayload = json.loads(salesPayload.replace("\'", "\""))
    else:
        salesPayload = None

    if salesRequestType == "":
        salesRequestType = "GET"
    salesSession = requests.Session()
    write_detail("ResultType"+str(salesResultType))
    sf = Salesforce(instance= instance , session_id = '')
    sf = Salesforce(username=salesId, password=salesPassword, security_token=securityToken, domain="login", session=salesSession)
    destinationFolder_salesforce= "wsl" + '_' +str(os.environ.get('WSL_LOAD_TABLE','')) + '_' + str(os.environ.get('WSL_SEQUENCE','')+'tmp')
    destinationPath = os.path.join(loadTableProperties['WSL_WORKDIR'],destinationFolder_salesforce)
    os.makedirs(destinationPath, exist_ok=True)
    salesHeaders = sf.headers
    if salesResultType == "XML":
        salesHeaders["Content-Type"] = "application/xml"
        salesHeaders["Accept"] = "application/xml"
    if salesResultType == "CSV" and salesforceQuery == "":
        response = requests.get(salesURL, headers=salesHeaders, cookies= {'sid': sf.session_id})
        download_report = response.content.decode('utf-8')
        df = pd.read_csv(StringIO(download_report))
        df.to_csv(os.path.join(destinationPath , "data.csv"), index=False , quoting=csv.QUOTE_NONE, sep='|', escapechar='\\')
        apiFileDownloadedPath = os.path.join(destinationPath , "data.csv")
    elif salesResultType == "JSON" and salesforceQuery != "":
        response = sf.query(salesforceQuery)
        with open(os.path.join(destinationPath ,'api.json'),'w',encoding='utf-8') as f:
            json.dump(response, f, ensure_ascii=False, indent=4)
        apiFileDownloadedPath = os.path.join(destinationPath ,'api.json')
    else:{%- br %}
        restAPI = WslApiFileBrowser.Auth(){%- br %}
        apiFileDownloadedPath = restAPI.userSessionCommonRequest(salesSession, loadTableProperties['salesRequestType'], loadTableProperties['salesforceUrl'], loadTableProperties['salesHeader'], loadTableProperties['salesPayload'], loadTableProperties['salesResultType']){%- br %}

    if "API_ERROR:" in apiFileDownloadedPath:
        write_error("Error in fetching API data")
        raise Exception("Error in fetching API data")

    if str(loadTableProperties['salesResultType']) == "JSON": {%- br %}
        loadTableProperties['sourceFileName'] = "api.json" {%- br %}
    if str(loadTableProperties['salesResultType']) == "XML": {%- br %}
        loadTableProperties['sourceFileName'] = "api.xml" {%- br %}
    if str(loadTableProperties['salesResultType']) == "CSV": {%- br %}
        loadTableProperties['sourceFileName'] = "data.csv" {%- br %}
    loadTableProperties['sourceFilePath'] = destinationPath {%- br %}
    {%- br %}
    {%- endif %}



    {%- if ['avro','orc', 'parquet', 'xlsx', 'csv', 'xml', 'json'] contains fileType and RunMode != "Database" %}
    # -- Init File Conversion Utility --------------------------------------------
    destination_directory_name = "wsl_" + str(os.environ.get('WSL_LOAD_TABLE','')) + "_" + str(os.environ.get('WSL_SEQUENCE','')) + "_csv"
    converted_file_destination_directory = os.path.join(loadTableProperties['WSL_WORKDIR'], destination_directory_name)

    fileConversionUtility = WslPythonCommon.FileConversion(
        sourceFilePath = loadTableProperties['sourceFilePath'],
        sourceFileName = loadTableProperties['sourceFileName'],
        destinationDirectory = converted_file_destination_directory,
        chunk_size = 100000,
    ){%- br %}

    {%- if ['csv'] contains fileType and (["AZ","GCS","S3"] contains RunMode)%}
    converted_file_destination_directory = converted_file_destination_directory.replace("_csv","_downloaded_files")
    {%- endif %}


    {% if RunMode == "S3" and (fileType != 'csv') and (fileType != 'xml') and (fileType != 'json')%}{%- br %}
    fileConversionUtility.s3_init(accessKey=loadTableProperties['awsAccessKey'], secretKey=loadTableProperties['awsSecretKey'], regionName=loadTableProperties['s3RegionName'])
    {% elseif RunMode == "AZ" and (fileType != 'csv') and (fileType != 'xml') and (fileType != 'json')%}{%- br %}
    fileConversionUtility.az_init(storage_account_name=loadTableProperties['azureStorageAccountName'], storage_account_key=loadTableProperties['azureStorageAccountAccessKey'], fileSystem=loadTableProperties['azureStorageFileSystem'])
    {%- endif %}
    {%- endif %}


    # -- Init Azure Blob Storage Utility --------------------------------------------
    connection_string = "DefaultEndpointsProtocol=https;AccountName={};AccountKey={};EndpointSuffix={}".format(extendedProperty['BLOB_STORAGE_ACCOUNT'], extendedProperty['BLOB_STORAGE_ACCESS_KEY'], extendedProperty['BLOB_ENDPOINT'])

    azure_blob_storage = WslPythonSQLServer.AzureBlobStorage(
        write_audit=write_audit,
        write_detail=write_detail,
        write_error=write_error,
        connection_string=connection_string,
        container_name=extendedProperty['BLOB_STORAGE_CONTAINER']
        )


    {%- if RunMode == "Windows" or RunMode == "S3" %}{%- br %}
    # ========================================================
    # = Init Archive Utility
    # ========================================================
    wslArchive = WslPythonCommon.ArchiveUtilsV2(
        write_audit=write_audit,
        write_detail=write_detail,
        write_error=write_error,
        source_directory=loadTableProperties['sourceFilePath'],{%br%}
        source_file_name=loadTableProperties['sourceFileName'],{%br%}
        {%- if isTriggerFilePresent == true %}
        trigger_directory=loadTableProperties['triggerFilePath'],{%br%}
        trigger_file_name=loadTableProperties['triggerFileName'],{%br%}
        {%- endif %}
        {%- if sourceFileArchiveMode == true %}
        source_destination_directory=loadTableProperties['source_destination_directory'],{%br%}
        source_destination_file_name=loadTableProperties['source_destination_file_name'],{%br%}
        {%- endif %}
        {%- if triggerFileArchiveMode == true %}
        trigger_destination_directory=loadTableProperties['trigger_destination_directory'],{%br%}
        trigger_destination_file_name=loadTableProperties['trigger_destination_file_name'],{%br%}
        {%- endif %}
        timeout=loadTableProperties['waitTime']{%br%}
    ){%br%}

    {%- if isTriggerFilePresent == true and RunMode == "Windows"%}{%br%}
    isTriggerFilePresent = wslArchive.wait_for_windows_file(check_for="TRIGGER"){%br%}
    if isTriggerFilePresent == False:
        write_error("Trigger File Not Found")
        exitCode = 2
        exitMessage = 'Trigger File Not Found'
        raise Exception('Trigger File Not Found')
    {%- endif %}
    {%- endif %}


    {%- if (RunMode == "Windows")%}{%- br %}
    isSourceFilePresent = wslArchive.wait_for_windows_file(check_for="SOURCE"){%br%}
    if isSourceFilePresent == False:
        write_error("Source File(s) Not Found")
        exitCode = 2
        exitMessage = 'Source File(s) Not Found'
        raise Exception('Source File(s) Not Found')
    {%- elseif (RunMode == "S3")%}{%- br %}
    wslArchive.s3_init(aws_access_key=loadTableProperties['awsAccessKey'],aws_secret_access_key=loadTableProperties['awsSecretKey'],region_name=loadTableProperties['s3RegionName'])
    {%- if table.loadInfo.wait %} {% br %}
    isSourceFilePresent= wslArchive.s3_wait_for_file()
    if isSourceFilePresent == False:
        write_error("Source File(s) Not Found")
        exitCode = 2
        exitMessage = 'Source File(s) Not Found'
        raise Exception('Source File(s) Not Found')
    {%- else %}{% br %}
    isSourceFilePresent= wslArchive.s3_file_exists(check_for="SOURCE")
    if isSourceFilePresent == False:
        write_error("Source File(s) Not Found")
        exitCode = 2
        exitMessage = 'Source File(s) Not Found'
        raise Exception('Source File(s) Not Found')
    {%- endif %}{% br %}
    {%- if isTriggerFilePresent == true%}{%- br %}
    isSourceFilePresent= wslArchive.s3_file_exists(check_for="TRIGGER")
    if isSourceFilePresent == False:
        write_error("Trigger File Not Found")
        exitCode = 2
        exitMessage = 'Trigger File Not Found'
        raise Exception('Trigger File Not Found')
    {%- endif %}{% br %}
    {%- endif %}{% br %}


    #--============================================================================{%br%}
    #-- Start Load Process - {{ RunMode }}{%br%}
    #--============================================================================{%br%}

    loadTableProperties['loadDetailList'] = []
    loadTableProperties['totalRowCount'] = 0

    write_audit("=================== Start Load Process - {{ RunMode }} ==================="){%br%}

    {%- if RunMode == "Database" %}{%- br %}
    #--============================================================================{%br%}
    #-- Create temporary files for Source Database{%br%}
    #--============================================================================{%br%}

    folderDownloadPath = os.path.join(loadTableProperties['WSL_WORKDIR'], "wsl" + '_' +str(os.environ.get('WSL_LOAD_TABLE','')) + '_' + str(os.environ.get('WSL_SEQUENCE','')))
    os.mkdir(folderDownloadPath)

    downloadedFileName = "wsl" + '_' + str(os.environ.get('WSL_LOAD_TABLE','')) + '_' + str(os.environ.get('WSL_SEQUENCE',''))

    write_audit("================= EXTRACT SQL ====================="){%br%}
    {%- set empty = "" %}
    {%- if table.loadInfo.selectDistinctValues == true %}
        {%- set distinct = true %}
    {% else %}
        {%- set distinct = false %}
    {%- endif %}
    {%- br %}
    {%- if table.loadInfo.overrideLoadSQL | trim != "" %}
    extractSql = """
        {{table.loadInfo.overrideLoadSQL}}{%- br %}
    """{%- br %}
    {% elseif table.loadInfo.useOverrideSourceColumns == true %}
    extractSql = """
        SELECT {%- if distinct%} DISTINCT{%- else %}{%- endif %}
        {{table.loadInfo.overrideSourceColumns}}{%- br %}
        {%- if table.loadInfo.sourceTables != "" -%}FROM """+str(os.environ.get('WSL_SRC_SCHEMA',''))+""".{{ table.loadInfo.sourceTables }} {{table.loadInfo.sourceTables }}{%- br %}{% endif %}
        {%- from table.loadInfo.whereAndGroupByClauses | lines as whereLine %}
        {{ whereLine }}{% br %}
        {%- endfrom %}
    """{%- br %}
    {% else %}
    extractSql = """
    SELECT {%- if distinct%} DISTINCT{%- else %}{%- endif %}
    {%- from table.columns as column where (column.sourceTable is defined or column.sourceColumn is defined or column.transformType.code == "D") %}
        {%- if not loop.first %}    , {% else %} {% endif %}
        {%- if column.transformType.code != "A" %}
        {{- column.source }}  AS {{column.name}}
        {%- else %}
        {%- if column.sourceTable is defined %}
            {%- fetch column.sourceTable %}
            {{- column.sourceTable.name }}.
        {%- endif %}
        {%- if column.sourceColumn is defined %}
            {{- column.sourceColumn.name }}
        {%- endif %}
        {%- endif %}
        {%- br %}
    {%- endfrom %}
    {% if table.loadInfo.sourceTables != "" -%}FROM {{table.loadInfo.sourceSchema}}.{{ table.loadInfo.sourceTables }} {{table.loadInfo.sourceTables }}{%- br %}{% endif %}
    {%- from table.loadInfo.whereAndGroupByClauses | lines as whereLine %}
    {{ whereLine }}{% br %}
    {%- endfrom %}
    """{%- br %}
    {%- endif %}

    source = f"{str(os.environ.get('WSL_SRC_DB',''))}.{str(os.environ.get('WSL_SRC_SCHEMA',''))}.{{table.loadInfo.sourceTables }}"

    write_detail("BEGIN create of data file from source system: "+str(datetime.now())){% br %}

    write_audit(extractSql)

    dataFile= os.path.join(folderDownloadPath,downloadedFileName) + '.' + 'csv'.lower()
    try:{%- br %}
        sourceDbType = "{{table.loadInfo.sourceConnection.dbType.name}}"{% br %}
        {%- if table.loadInfo.sourceConnection.dbType.name == "Oracle" %}
        result = WslPythonCommon.GetDataToFileFromOracle(extractSql,str(os.environ.get('WSL_SRC_SERVER','')),str(os.environ.get('WSL_SRC_USER','')),str(os.environ.get('WSL_SRC_PWD','')),
            dataFile,str(extendedProperty['UNLOAD_DELIMITER']), extendedProperty['SPLIT_THRESHOLD'], True, unicode,
            str(extendedProperty['UNLOAD_ENC']), str(extendedProperty['UNLOAD_ESC']), True, 'csv', None,sourceDbType){% br %}
        {%- else %}
        result = WslPythonCommon.GetDataToFileV3(extractSql,str(os.environ.get('WSL_SRC_DSN','')),str(os.environ.get('WSL_SRC_USER','')),str(os.environ.get('WSL_SRC_PWD','')),
            dataFile,str(extendedProperty['UNLOAD_DELIMITER']), extendedProperty['SPLIT_THRESHOLD'], True, unicode,
            str(extendedProperty['UNLOAD_ENC']), str(extendedProperty['UNLOAD_ESC']), True, 'csv', None,sourceDbType){% br %}
        {%- endif %}
    except Exception as exceptionError:{%- br %}
        write_error("Failed to generated datafiles: " + str(exceptionError))
        write_error(traceback.format_exc())
        exitCode = 2
        exitMessage = 'Script failed to create data file from source system'
        raise Exception('Script failed to create data file from source system')

    if result[0]== -2:
        error_message = result[1]
        write_error("Failed to generated datafiles: " + str(error_message))
        exitCode = 2
        exitMessage = 'Script failed to create data file from source system'
        raise Exception('Script failed to create data file from source system')
    elif result[0]==1 and result[1] < 1:
        write_audit("Source query returned 0 rows")

    write_detail("END create of data file from source system: "+str(datetime.now())){% br %}

    #For multiple input files add file name to list
    dataFiles = []{% br %}
    for f in glob.iglob(os.path.join(folderDownloadPath,downloadedFileName)+'*.' + 'csv'): {% br %}
        dataFiles.append(f){% br %}

    #Set values in load table properties
    loadTableProperties['dataFileList']   =  dataFiles
    loadTableProperties['rowCount']       = result[1]
    loadTableProperties['sourceFilePath'] = folderDownloadPath
    {%- endif %}


    # Load Data
    write_audit("================= LOAD DATA ====================="){%br%}
    {%- if RunMode == "Database" %}{%- br %}


    {%- if ServerType == "AZSQL" %}

    loadTableProperties['blob_name'] = "WSL_" + str(os.environ.get('WSL_LOAD_TABLE','')) + "_" + str(os.environ.get('WSL_SEQUENCE',''))

    for dataFile in dataFiles:{%br%}
        azure_blob_storage.upload(dataFile, loadTableProperties['blob_name'])


    list_of_files = WslPythonSQLServer.list_files_in_folder(extendedProperty['BLOB_STORAGE_ACCESS_KEY'],extendedProperty['BLOB_STORAGE_ACCOUNT'],extendedProperty['BLOB_STORAGE_CONTAINER'],loadTableProperties['blob_name'])

    # -- Load Data --------------------------------------------
    for file in list_of_files:
        drop_temp_table()
        create_temp_table()
        load_start_time = datetime.now(){%br%}
        row_count, status = load_data(file){%br%}
        load_end_time = datetime.now(){%br%}
        time_taken = load_end_time - load_start_time{%br%}
        source_extension = (loadTableProperties['sourceFileName']).split(".")[-1]
        file = file.split('.')[0] + '.' + source_extension
        loadTableProperties['loadDetailList'].append(
            {'source' : file,
            'row_count' : row_count,
            'time_taken' : round(time_taken.total_seconds(), 2),
            'status' : 'Success' if status else 'Failed'}
        ){%br%}
        insert_row_count = insert_data(){%br%}
        loadTableProperties['totalRowCount'] += insert_row_count{%br%}

    {%- else %}

    for dataFile in dataFiles:{%br%}
        drop_temp_table()
        create_temp_table()
        load_start_time = datetime.now(){%br%}
        row_count, status = load_data(dataFile){%br%}
        load_end_time = datetime.now(){%br%}
        time_taken = load_end_time - load_start_time{%br%}
        loadTableProperties['loadDetailList'].append(
            {'source' : f'{{table.loadInfo.sourceTables }}',
            'row_count' : row_count,
            'time_taken' : round(time_taken.total_seconds(), 2),
            'status' : 'Success' if status else 'Failed'}
            ){%br%}
        insert_row_count = insert_data(){%br%}
        loadTableProperties['totalRowCount'] += insert_row_count{%br%}

    {%- endif -%}


    {%- elseif ["AZ","S3","GCS"] contains RunMode and fileType == "csv" %}{%- br %}{%- br %}
    # -- Download CSV File from Cloud Sources to local --------------------------------------------

    {%- if RunMode ==  "S3"%}{%- br %}{%- br %}
    try:
        download_file_from_amazonS3 = WslPythonCommon.downloadFileFromAmazonS3(loadTableProperties['awsAccessKey'],loadTableProperties['awsSecretKey'],loadTableProperties['s3RegionName'],loadTableProperties['s3BucketName'],loadTableProperties['sourceFilePath'],loadTableProperties['sourceFileName'],converted_file_destination_directory)

    except Exception as e:
        write_error(f"Failed to download file from Amazon S3: {str(e)}")
        write_error(traceback.format_exc())
        exitCode = 2
        exitMessage = 'Script failed to download file from Amazon S3'
        raise e

    {%- elseif RunMode ==  "AZ"%}{%- br %}{%- br %}

    try:
        download_file_from_azureDataLake = WslPythonCommon.downloadFileFromAzureDataLake(loadTableProperties['azureStorageAccountName'],loadTableProperties['azureStorageAccountAccessKey'],loadTableProperties['azureStorageFileSystem'],"",loadTableProperties['sourceFileName'],converted_file_destination_directory)

    except Exception as e:
        write_error(f"Failed to download file from Azure Datalake: {str(e)}")
        write_error(traceback.format_exc())
        exitCode = 2
        exitMessage = 'Script failed to download file from Azure Datalake'
        raise e
    {%br%}
    {%- elseif RunMode ==  "GCS"%}{%- br %}{%- br %}

    try:
        download_file_from_googleCloudStorage = WslPythonCommon.downloadFileFromGoogleCloudV2(loadTableProperties['sourceFilePath'],loadTableProperties['sourceFileName'],converted_file_destination_directory)

    except Exception as e:
        write_error(f"Failed to download file from GCS: {str(e)}")
        write_error(traceback.format_exc())
        exitCode = 2
        exitMessage = 'Script failed to download file from GCS'
        raise e

    {%- endif %}

    {%- elseif ["xml","json"] contains fileType %}{%- br %}{%- br %}

    headers = """{%- br %}
    {%- from table.columns as column where (column.sourceTable is defined or column.sourceColumn is defined or column.transformType.code == "D") %}
    {%- set sourceColumnName = "" -%}
    {%- if column.sourceColumn is defined and column.name is defined and column.transformType.code != "A"-%}
        {%- set sourceColumnName = column.sourceColumn.name | trim -%}
    {%- endif -%}
    {{sourceColumnName}}{% br %}
    {%- if not loop.last -%}
    ,
    {%- endif -%}
    {%- endfrom -%}"""{% br %}
    {%- br %}

    headers = headers.replace("\n", "").replace(" ", "")

    {%- if ["AZ","S3","GCS"] contains RunMode %}{%- br %}
    temp_destination_directory = converted_file_destination_directory.replace('_csv', '_downloaded_files')
    os.makedirs(temp_destination_directory, exist_ok=True)

    {%- if RunMode ==  "S3"%}{%- br %}{%- br %}
    try:
        download_file_from_amazonS3 = WslPythonCommon.downloadFileFromAmazonS3(loadTableProperties['awsAccessKey'],loadTableProperties['awsSecretKey'],loadTableProperties['s3RegionName'],loadTableProperties['s3BucketName'],loadTableProperties['sourceFilePath'],loadTableProperties['sourceFileName'],temp_destination_directory)
    except Exception as e:
        write_error(f"Failed to download file from Amazon S3: {str(e)}")
        write_error(traceback.format_exc())
        exitCode = 2
        exitMessage = 'Script failed to download file from Amazon S3'
        raise e


    {%- elseif RunMode ==  "AZ"%}{%- br %}{%- br %}
    try:
        download_file_from_azureDataLake = WslPythonCommon.downloadFileFromAzureDataLake(loadTableProperties['azureStorageAccountName'],loadTableProperties['azureStorageAccountAccessKey'],loadTableProperties['azureStorageFileSystem'],"",loadTableProperties['sourceFileName'],temp_destination_directory)
    except Exception as e:
        write_error(f"Failed to download file from Azure Datalake: {str(e)}")
        write_error(traceback.format_exc())
        exitCode = 2
        exitMessage = 'Script failed to download file from Azure Datalake'
        raise e
    {%br%}
    {%- elseif RunMode ==  "GCS"%}{%- br %}{%- br %}
    try:
        download_file_from_googleCloudStorage = WslPythonCommon.downloadFileFromGoogleCloudV2(loadTableProperties['sourceFilePath'],loadTableProperties['sourceFileName'],temp_destination_directory)
    except Exception as e:
        write_error(f"Failed to download file from GCS: {str(e)}")
        write_error(traceback.format_exc())
        exitCode = 2
        exitMessage = 'Script failed to download file from Google Cloud Storage'
        raise e
    {%- endif %}

    {%- if fileType == "json" %}{%- br %}
    path_to_wslJsonToCsv = r"$WSL_SCRIPT_wslJsonToCsv_CODE$"{%- br %}
    import wslJsonToCsv{%- br %}
    wslJsonToCsv.jsonToCsv(os.path.join(temp_destination_directory,loadTableProperties['sourceFileName']), unicode,fileConversionUtility._get_csv_file_path(os.path.join(temp_destination_directory,loadTableProperties['sourceFileName']), converted_file_destination_directory), headers.replace("\r\n","").split(','),[], extendedProperty['UNLOAD_DELIMITER'], extendedProperty['UNLOAD_ENC'], extendedProperty['UNLOAD_ESC'], True){%- br %}
    {%- elseif fileType == "xml" %}{%- br %}
    path_to_wslXmlToCsv = r"$WSL_SCRIPT_wslXmlToCsv_CODE$"{%- br %}
    import wslXmlToCsv{%- br %}
    wslXmlToCsv.xmlToCsv(os.path.join(temp_destination_directory,loadTableProperties['sourceFileName']), unicode,fileConversionUtility._get_csv_file_path(os.path.join(temp_destination_directory,loadTableProperties['sourceFileName']), converted_file_destination_directory), headers.replace("\r\n","").split(','),[], extendedProperty['UNLOAD_DELIMITER'], extendedProperty['UNLOAD_ENC'], extendedProperty['UNLOAD_ESC'], True){%- br %}
    {%- endif %}

    {%- elseif RunMode == "Windows" or RunMode == "REST" or RunMode == "Salesforce"%}

    {%- if (fileType == "json")%}{%- br %}
    path_to_wslJsonToCsv = r"$WSL_SCRIPT_wslJsonToCsv_CODE$"{%- br %}
    import wslJsonToCsv{%- br %}
    {%- else %}{%- br %}
    path_to_wslXmlToCsv = r"$WSL_SCRIPT_wslXmlToCsv_CODE$"{%- br %}
    import wslXmlToCsv{%- br %}
    {%- endif %}

    file_path = os.path.join(loadTableProperties['sourceFilePath'],loadTableProperties['sourceFileName'])
    files = glob.glob(file_path)


    for file_Path in files:
        {%- if (fileType == "json")%}{%- br %}
        wslJsonToCsv.jsonToCsv(file_Path, unicode, fileConversionUtility._get_csv_file_path(file_Path, converted_file_destination_directory), headers.replace("\r\n","").split(','),[],extendedProperty['UNLOAD_DELIMITER'], extendedProperty['UNLOAD_ENC'], extendedProperty['UNLOAD_ESC'], True){%- br %}
        {%- else %}{%- br %}
        wslXmlToCsv.xmlToCsv(file_Path, unicode,fileConversionUtility._get_csv_file_path(file_Path, converted_file_destination_directory), headers.replace("\r\n","").split(','),[],extendedProperty['UNLOAD_DELIMITER'], extendedProperty['UNLOAD_ENC'], extendedProperty['UNLOAD_ESC'], True){%- br %}
        {%- endif %}

    {%- endif %}

    {%- else -%}

    {%- if fileType == 'orc' %}
    # -- Convert ORC File To CSV --------------------------------------------
    fileConversionUtility.convert_orc_to_csv(
        delimiter = str(extendedProperty['UNLOAD_DELIMITER']),
        field_enclosure = str(extendedProperty['UNLOAD_ENC']),
        escape_char = str(extendedProperty['UNLOAD_ESC'])
    )

    {%- endif %}

    {%- if fileType == 'parquet' %}
    # -- Convert Parquet File To CSV --------------------------------------------
    fileConversionUtility.convert_parquet_to_csv(
        delimiter = str(extendedProperty['UNLOAD_DELIMITER']),
        field_enclosure = str(extendedProperty['UNLOAD_ENC']),
        escape_char = str(extendedProperty['UNLOAD_ESC'])
    )
    {%- endif %}

    {%- if fileType == 'avro' %}
    # -- Convert Avro File To CSV --------------------------------------------
    fileConversionUtility.convert_avro_to_csv(
        delimiter = str(extendedProperty['UNLOAD_DELIMITER']),
        field_enclosure = str(extendedProperty['UNLOAD_ENC']),
        escape_char = str(extendedProperty['UNLOAD_ESC'])
    )
    {%- endif %}

    {%- if fileType == 'xlsx' %}
    # -- Convert XLSX File To CSV --------------------------------------------
    fileConversionUtility.convert_excel_to_csv(
        delimiter = str(extendedProperty['UNLOAD_DELIMITER']),
        field_enclosure = str(extendedProperty['UNLOAD_ENC']),
        escape_char = str(extendedProperty['UNLOAD_ESC']),
        sheetname = str(loadTableProperties['sourceFileSheetName'])
    )
    {%- endif %}

    {%- endif %}{%br%}

    {%br%}
    {%- if (['avro','orc', 'parquet', 'xlsx', 'json', 'xml'] contains fileType) and RunMode != "Database" %}

    # ========================================================
    # = Upload Source File(s) To Azure Blob Storage
    # ========================================================

    {%- if ServerType == "AZSQL" %}

    loadTableProperties['blob_name'] = "WSL_" + str(os.environ.get('WSL_LOAD_TABLE','')) + "_" + str(os.environ.get('WSL_SEQUENCE','')){%br%}
    {%br%}
    azure_blob_storage.upload(str(fileConversionUtility.output_directory), loadTableProperties['blob_name']){%br%}
    {%br%}
    list_of_files = WslPythonSQLServer.list_files_in_folder(extendedProperty['BLOB_STORAGE_ACCESS_KEY'],extendedProperty['BLOB_STORAGE_ACCOUNT'],extendedProperty['BLOB_STORAGE_CONTAINER'],loadTableProperties['blob_name'])

    # -- Load Data --------------------------------------------
    for file in list_of_files:
        drop_temp_table()
        create_temp_table()
        load_start_time = datetime.now(){%br%}
        row_count, status = load_data(file){%br%}
        load_end_time = datetime.now(){%br%}
        time_taken = load_end_time - load_start_time{%br%}
        source_extension = (loadTableProperties['sourceFileName']).split(".")[-1]
        file = file.split('.')[0] + '.' + source_extension
        loadTableProperties['loadDetailList'].append(
            {'source' : file,
            'row_count' : row_count,
            'time_taken' : round(time_taken.total_seconds(), 2),
            'status' : 'Success' if status else 'Failed'}
        ){%br%}
        insert_row_count = insert_data(){%br%}
        loadTableProperties['totalRowCount'] += insert_row_count{%br%}

    {%- else %}

    # -- Load Data --------------------------------------------
    for file in os.listdir(str(fileConversionUtility.output_directory)):
        drop_temp_table()
        create_temp_table()
        load_start_time = datetime.now(){%br%}
        row_count, status = load_data(os.path.join(str(fileConversionUtility.output_directory), file)){%br%}
        load_end_time = datetime.now(){%br%}
        time_taken = load_end_time - load_start_time{%br%}
        source_extension = (loadTableProperties['sourceFileName']).split(".")[-1]
        file = file.split('.')[0] + '.' + source_extension
        loadTableProperties['loadDetailList'].append(
            {'source' : file,
            'row_count' : row_count,
            'time_taken' : round(time_taken.total_seconds(), 2),
            'status' : 'Success' if status else 'Failed'}
        ){%br%}
        insert_row_count = insert_data(){%br%}
        loadTableProperties['totalRowCount'] += insert_row_count{%br%}
    {%- endif %}
    {%- endif %}

    {%- if fileType == 'csv' and RunMode != "Database" %}

    {%- if ServerType == "AZSQL" %}

    filePath = os.path.join(loadTableProperties['sourceFilePath'], loadTableProperties['sourceFileName'])
    loadTableProperties['blob_name'] = "WSL_" + str(os.environ.get('WSL_LOAD_TABLE','')) + "_" + str(os.environ.get('WSL_SEQUENCE','')){%br%}

    {%- if  RunMode == "Windows" or RunMode == "REST" or RunMode == "Salesforce" %}{%br%}
    azure_blob_storage.upload(filePath, loadTableProperties['blob_name']){%br%}
    {%- else -%}{%br%}
    azure_blob_storage.upload(converted_file_destination_directory, loadTableProperties['blob_name']){%br%}
    {%- endif %}{%br%}

    list_of_files = WslPythonSQLServer.list_files_in_folder(extendedProperty['BLOB_STORAGE_ACCESS_KEY'],extendedProperty['BLOB_STORAGE_ACCOUNT'],extendedProperty['BLOB_STORAGE_CONTAINER'],loadTableProperties['blob_name'])

    for file in list_of_files:
        drop_temp_table()
        create_temp_table()
        load_start_time = datetime.now(){%br%}
        row_count, status = load_data(file){%br%}
        load_end_time = datetime.now(){%br%}
        time_taken = load_end_time - load_start_time{%br%}
        loadTableProperties['loadDetailList'].append(
            {'source' : file,
            'row_count' : row_count,
            'time_taken' : round(time_taken.total_seconds(), 2),
            'status' : 'Success' if status else 'Failed'
            }
        ){%br%}
        insert_row_count = insert_data(){%br%}
        loadTableProperties['totalRowCount'] += insert_row_count{%br%}

    {% else %}
    # -- Load Data --------------------------------------------{%br%}

    {%- if  RunMode == "Windows" or RunMode == "REST" or RunMode == "Salesforce"%}{%br%}
    filePath = os.path.join(loadTableProperties['sourceFilePath'], loadTableProperties['sourceFileName']){%br%}
    {%- else -%}{%br%}
    filePath = os.path.join(converted_file_destination_directory, loadTableProperties['sourceFileName']){%br%}
    {%- endif %}
    {%br%}
    for file in glob.glob(filePath):
        drop_temp_table()
        create_temp_table()
        load_start_time = datetime.now(){%br%}
        row_count, status = load_data(file){%br%}
        load_end_time = datetime.now(){%br%}
        time_taken = load_end_time - load_start_time{%br%}
        loadTableProperties['loadDetailList'].append(
            {'source' : file,
            'row_count' : row_count,
            'time_taken' : round(time_taken.total_seconds(), 2),
            'status' : 'Success' if status else 'Failed'
            }
        ){%br%}
        insert_row_count = insert_data(){%br%}
        loadTableProperties['totalRowCount'] += insert_row_count{%br%}

    {%- endif %}
    {%- endif %}

    # Drop Temporary Table
    write_audit("================= DROP TEMP TABLE ====================="){%br%}
    drop_temp_table()

    # Construct Load Summary Message
    write_audit("Source                                            " + "Status         " + "Rows Loaded        "+"Time Taken"){%- br %}
    write_audit("--------------------------------------------------  " + "-------------- " + "------------------ "+"----------"){%- br %}

    for loadDetail in loadTableProperties['loadDetailList']:{%- br %}
        write_audit(loadDetail['source'] + "  " + loadDetail['status'] + "  " + str(loadDetail['row_count']) + "  " + str(loadDetail['time_taken']) + " seconds"){%- br %}

    write_audit("")
    write_audit("Total Rows Inserted In Table: " + str(loadTableProperties['totalRowCount'])){%br%}
    write_audit("Load Completed Successfully"){%br%}

    {%- if sourceFileArchiveMode == true and RunMode =='Windows' %}
    {%- br %}
    wslArchive.windows_archive(check_for="SOURCE"){%- br %}
    {%- elseif sourceFileArchiveMode == true and RunMode =='S3' %}
    {%- br %}
    wslArchive.s3_archive(check_for="SOURCE"){%- br %}
    {%- endif %}

    {%- if triggerFileArchiveMode == true and RunMode =='Windows' %}
    {%- br %}
    wslArchive.windows_archive(check_for="TRIGGER"){%- br %}
    {%- elseif triggerFileArchiveMode == true and RunMode =='S3' %}
    {%- br %}
    wslArchive.s3_archive(check_for="TRIGGER"){%- br %}
    {%- endif %}

    if extendedProperty['DEBUG'].upper() == 'FALSE':{%- br %}
    {%- if RunMode =='Database' %}{%- br %}
        shutil.rmtree(folderDownloadPath)
    {%- else %}{%- br %}
        fileConversionUtility.clear_temporary_directory()
    {%- endif %}

    {%- if ServerType =='AZSQL' %}{%- br %}
        azure_blob_storage.delete(loadTableProperties['blob_name'])
    {%- endif %}
{%- br %}
except Exception as e: {%- br %}
    write_error("Script Failed:" + str(e))
    write_error(traceback.format_exc())
    exitCode = 2
    exitMessage = 'Script run failed'
{%- br %}
else: {%- br %}
    exitCode = 0
    exitMessage = 'Script ran successfully'
{%- br %}
finally: {%- br %}
    exit_script(exitCode, exitMessage)
{%- br %}
